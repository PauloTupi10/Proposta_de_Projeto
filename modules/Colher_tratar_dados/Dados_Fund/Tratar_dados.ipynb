{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definindo as funções"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções Básicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def endereco_arquivos(Ticker):\n",
    "    ## Arquivos de Dados\n",
    "    # Dados Fundamentalistas\n",
    "    ticker_Fund = f\"{Ticker}_Fund.parquet\"\n",
    "    arquivo_Fund = os.path.join(\"..\",\"..\",\"..\",\"dataset\", \"BR\", \"ACOES\", \"Dados_Brutos\",ticker_Fund)\n",
    "    # Cotações Diárias\n",
    "    ticker_Cot = f\"{Ticker}_Cot.parquet\"\n",
    "    arquivo_Cot = os.path.join(\"..\",\"..\",\"..\",\"dataset\", \"BR\", \"ACOES\", \"Dados_Brutos\",ticker_Cot)\n",
    "    # Dados de Proventos\n",
    "    ticker_Prov = f\"{Ticker}_Prov.parquet\"\n",
    "    arquivo_Prov = os.path.join(\"..\",\"..\",\"..\",\"dataset\", \"BR\", \"ACOES\", \"Dados_Brutos\",ticker_Prov)\n",
    "    # Dados de Eventos como desdobramentos e grupamentos\n",
    "    ticker_Eventos = f\"{Ticker}_Eventos.parquet\"\n",
    "    arquivo_Eventos = os.path.join(\"..\",\"..\",\"..\",\"dataset\", \"BR\", \"ACOES\", \"Dados_Brutos\",ticker_Eventos)\n",
    "    # Dados de Subscrições\n",
    "    ticker_Subscricao = f\"{Ticker}_Subscricao.parquet\"\n",
    "    arquivo_Subscricao = os.path.join(\"..\",\"..\",\"..\",\"dataset\", \"BR\", \"ACOES\", \"Dados_Brutos\",ticker_Subscricao)\n",
    "\n",
    "    return arquivo_Fund, arquivo_Cot, arquivo_Prov, arquivo_Eventos, arquivo_Subscricao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Func_Classe_acao(Ticker):\n",
    "    if Ticker[4] == \"3\":\n",
    "        Classe_acao = \"ON\"\n",
    "    elif Ticker[4] == \"4\":\n",
    "        Classe_acao = \"PN\"\n",
    "    elif Ticker[4] == \"5\":\n",
    "        Classe_acao = \"PNA\"\n",
    "    elif Ticker[4] == \"6\":\n",
    "        Classe_acao = \"PNB\"\n",
    "    elif Ticker[4:6] == \"11\":\n",
    "        Classe_acao = \"UNT\"\n",
    "    else:\n",
    "        Classe_acao = \"ERRO\"\n",
    "        \n",
    "    return Classe_acao"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tratar dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tratar_Fund(arquivo_Fund):\n",
    "    # Lendo os arquivos\n",
    "    df_fund = pd.read_parquet(arquivo_Fund)\n",
    "\n",
    "\n",
    "    # Ao ler o arquivo Parquet, especifique o dtype usando o parâmetro dtype\n",
    "    df_fund = pd.read_parquet(arquivo_Fund)\n",
    "\n",
    "    # Excluir o que não tem Data_balanco\n",
    "    df_fund = df_fund.dropna(subset=[\"Data_balanco\",\"Num_acoes\",\"Market_value\"])\n",
    "\n",
    "    # Colunas que são datas\n",
    "    colunas_datas = ['Data_balanco', 'Data_demonstracao', 'Data_analise']  # Substitua pelos nomes reais das suas colunas de datas\n",
    "    df_fund.loc[:, colunas_datas] = df_fund.loc[:, colunas_datas].apply(pd.to_datetime, format='%d/%m/%Y')\n",
    "    df_fund.index = pd.to_datetime(df_fund.index, format='%d/%m/%Y')\n",
    "\n",
    "    # Suponha que você tenha uma lista de nomes de colunas que devem ser lidas como números\n",
    "    colunas_numericas = ['Num_acoes', 'Fator_equivalencia_acoes',\n",
    "        'Market_value', 'PL', 'RL', 'EBITDA', 'D&A', 'EBIT', 'LL',\n",
    "        'LL_controlador', 'LL_nao_controlador', 'ROIC', 'ROE', 'Div_Bruta',\n",
    "        'Div_liq', 'Div_Arrendamento', 'FCO', 'FCI', 'FCF', 'Preco_fechamento',\n",
    "        'Payout', 'Proventos', 'JCP',\n",
    "        'DY_12m', \"DY_24m\", \"DY_36m\", \"DY_48m\", \"DY_60m\",\n",
    "        'ret_12meses', 'ret_1mes_aa', 'ret_ano', 'ret_CDI_1m',\n",
    "        'ret_CDI_12m', 'ret_CDI_ano', 'ret_IBOV_1mes', 'ret_IBOV_12m',\n",
    "        'ret_IBOV_ano',\n",
    "        'meses']  # Substitua pelos nomes reais das suas colunas numéricas\n",
    "    df_fund.fillna(0,inplace=True)\n",
    "    for col in colunas_numericas:\n",
    "        # Substitua vírgulas por pontos e converta para float\n",
    "        try:\n",
    "            df_fund[col] = df_fund[col].str.replace(',', '.').astype(float)\n",
    "        except:\n",
    "            print(f\"Erro na coluna {col}\")\n",
    "        pass\n",
    "\n",
    "    df_fund.fillna(0,inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "    # Colunas que são porcentagem\n",
    "    colunas_pct = ['DY_12m', \"DY_24m\", \"DY_36m\", \"DY_48m\", \"DY_60m\",\n",
    "                   'ret_12meses', 'ret_1mes_aa', 'ret_ano', 'ret_CDI_1m',\n",
    "        'ret_CDI_12m', 'ret_CDI_ano', 'ret_IBOV_1mes', 'ret_IBOV_12m',\n",
    "        'ret_IBOV_ano']  # Substitua pelos nomes reais das suas colunas de porcentagem\n",
    "\n",
    "    df_fund.loc[:, colunas_pct] = df_fund.loc[:, colunas_pct].apply(lambda x: x/100)\n",
    "\n",
    "    df_fund.sort_index(ascending=False, inplace=True)\n",
    "    return df_fund"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tratar_cot(arquivo_Cot):\n",
    "    # Lendo os arquivos de cotações\n",
    "    df_cot = pd.read_parquet(arquivo_Cot)\n",
    "    # Colunas que são datas\n",
    "    df_cot.index = pd.to_datetime(df_cot.index, format='%d/%m/%Y')\n",
    "\n",
    "    # Substitua os valores vazios (\"\" ou string vazia) por NaN em todas as colunas\n",
    "    df_cot.replace(\"\", np.nan, inplace=True)\n",
    "\n",
    "    # Excluir o que não tem Fech_Historico\n",
    "    df_cot = df_cot.dropna(subset=[\"Fech_Historico\"])\n",
    "\n",
    "\n",
    "    # Colunas que são numéricas\n",
    "    colunas_numericas = ['Fech_Ajustado', 'Variação(%)','Fech_Historico', 'Abertura_Ajustado',\n",
    "        'Min_Ajustado', 'Medio_Ajustado', 'Max_Ajustado', 'Vol(MM_R$)',\n",
    "        'Negocios', 'Fator']\n",
    "    for col in colunas_numericas:\n",
    "        # Substitua vírgulas por pontos e converta para float\n",
    "        try:\n",
    "            df_cot[col] = df_cot[col].str.replace(',', '.').astype(float)\n",
    "        except:\n",
    "            raise\n",
    "\n",
    "\n",
    "    # Colunas que são porcentagem\n",
    "    colunas_pct = ['Variação(%)']\n",
    "    # Substitua os valores None por NaN em todas as colunas\n",
    "    df_cot.fillna(0, inplace=True)\n",
    "    df_cot.loc[:, colunas_pct] = df_cot.loc[:, colunas_pct].apply(lambda x: x/100)\n",
    "\n",
    "    # Ordenar por index\n",
    "    df_cot.sort_index(ascending=False, inplace=True)\n",
    "\n",
    "    return df_cot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tratar_prov(arquivo_Prov, Classe_acao):\n",
    "    # Lendo os arquivos de proventos\n",
    "    try:\n",
    "        Existe_prov = True\n",
    "        df_prov = pd.read_parquet(arquivo_Prov)\n",
    "\n",
    "        # Colunas que são datas\n",
    "        df_prov.index = pd.to_datetime(df_prov.index, format='%d/%m/%Y')\n",
    "\n",
    "        # Substitua os valores vazios (\"\" ou string vazia) por NaN em todas as colunas\n",
    "        df_prov.replace(\"\", np.nan, inplace=True)\n",
    "\n",
    "        # Excluir o que não tem Valor_do_Provento\n",
    "        df_prov = df_prov.dropna(subset=[\"Valor_do_Provento\"])\n",
    "\n",
    "        # Colunas que são numéricas\n",
    "        colunas_numericas = ['Valor_do_Provento', 'Último_preco_com', 'Provento_por']\n",
    "        # Ordenar por index\n",
    "        df_prov.sort_index(ascending=False, inplace=True)\n",
    "        # Filtra a classe da ação\n",
    "        df_prov = df_prov.loc[(df_prov[\"Tipo\"]==Classe_acao) | (df_prov[\"Tipo\"]==\"todas\"),:].copy()\n",
    "        \n",
    "        for col in colunas_numericas:\n",
    "            # Substitua vírgulas por pontos e converta para float\n",
    "            try:\n",
    "                df_prov[col] = df_prov[col].str.replace(',', '.').astype(float)\n",
    "            except:\n",
    "                raise\n",
    " \n",
    "    except:\n",
    "        Existe_prov = False\n",
    "        df_prov = pd.DataFrame()\n",
    "\n",
    "    return df_prov, Existe_prov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tratar_even(arquivo_Eventos, Classe_acao):\n",
    "    # Lendo os arquivos de eventos\n",
    "    try:\n",
    "        Existe_eventos = True\n",
    "        df_eventos = pd.read_parquet(arquivo_Eventos)\n",
    "\n",
    "        # Colunas que são datas\n",
    "        df_eventos.index = pd.to_datetime(df_eventos.index, format='%d/%m/%Y')\n",
    "        colunas_numericas = ['Fator']\n",
    "        # Filtra a classe da ação\n",
    "        df_eventos = df_eventos.loc[(df_eventos[\"ClasseAcao\"]==Classe_acao) | (df_eventos[\"ClasseAcao\"]==\"todas\"),:].copy()\n",
    "        # Ordenar por index\n",
    "        df_eventos.sort_index(ascending=False, inplace=True)\n",
    "        # Colunas que são numéricas\n",
    "        for col in colunas_numericas:\n",
    "            # Substitua vírgulas por pontos e converta para float\n",
    "            try:\n",
    "                df_eventos[col] = df_eventos[col].str.replace(',', '.').astype(float)\n",
    "            except:\n",
    "                raise\n",
    "\n",
    "    except:\n",
    "        Existe_eventos = False\n",
    "        df_eventos = pd.DataFrame()\n",
    "    \n",
    "\n",
    "    return df_eventos, Existe_eventos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tratar_subs(arquivo_Subscricao):\n",
    "    # Lendo os arquivos de subscrições\n",
    "    try:\n",
    "        Existe_subscricao = True\n",
    "        df_subscricao = pd.read_parquet(arquivo_Subscricao)\n",
    "        # Colunas que são datas\n",
    "        df_subscricao.index = pd.to_datetime(df_subscricao.index, format='%d/%m/%Y')\n",
    "\n",
    "        # Substitua os valores vazios (\"\" ou string vazia) por NaN em todas as colunas\n",
    "        df_subscricao.replace(\"\", np.nan, inplace=True)\n",
    "\n",
    "        # Excluir o que não tem Valor_do_Provento\n",
    "        df_subscricao = df_subscricao.dropna(subset=[\"Fator\"])\n",
    "\n",
    "        # Colunas que são numéricas\n",
    "        colunas_numericas = ['Fator', 'Preco_Subscricao']\n",
    "\n",
    "        # Ordenar por index\n",
    "        df_subscricao.sort_index(ascending=False, inplace=True)\n",
    "        # Filtra a classe da ação\n",
    "        df_subscricao = df_subscricao.loc[(df_subscricao[\"ClasseAcao\"]==Classe_acao) | (df_subscricao[\"ClasseAcao\"]==\"todas\"),:].copy()\n",
    "\n",
    "        for col in colunas_numericas:\n",
    "        # Substitua vírgulas por pontos e converta para float\n",
    "            try:\n",
    "                df_subscricao[col] = df_subscricao[col].str.replace(',', '.').astype(float)\n",
    "            except:\n",
    "                raise\n",
    "        \n",
    "    except:\n",
    "        Existe_subscricao = False\n",
    "        df_subscricao = pd.DataFrame()\n",
    "\n",
    "\n",
    "\n",
    "    return df_subscricao, Existe_subscricao"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizar_dados_fund(df_fund, df_eventos, Existe_eventos, Ticker):\n",
    "    # Normalizar Dados Fundamentalistas e considerar os eventos\n",
    "    df_Tratar_por_Acao = df_fund.copy()\n",
    "\n",
    "    ## Calcular o número de ações Equivalentes atual\n",
    "    # Criar a Coluna de Número de Ações Equivalentes\n",
    "    df_Tratar_por_Acao.insert(3, \"Num_acoes_equivalentes\", 0)\n",
    "\n",
    "    ## No caso de Units é necessário considerar o número de ações de cada classe\n",
    "    df_Tratar_por_Acao.loc[:, \"Num_acoes_equivalentes\"]= df_Tratar_por_Acao.apply(lambda x: x[\"Num_acoes\"] / x[\"Fator_equivalencia_acoes\"], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "    ## Adicionar o Ticker\n",
    "    df_Tratar_por_Acao.insert(0, \"Ticker\", Ticker)\n",
    "\n",
    "    ## Adicionar o Coluna de Proventos\n",
    "    df_Tratar_por_Acao.insert(len(df_Tratar_por_Acao.columns), \"Prov_12meses\", 0)\n",
    "    df_Tratar_por_Acao.insert(len(df_Tratar_por_Acao.columns), \"Prov_24meses\", 0)\n",
    "    df_Tratar_por_Acao.insert(len(df_Tratar_por_Acao.columns), \"Prov_36meses\", 0)\n",
    "    df_Tratar_por_Acao.insert(len(df_Tratar_por_Acao.columns), \"Prov_48meses\", 0)\n",
    "    df_Tratar_por_Acao.insert(len(df_Tratar_por_Acao.columns), \"Prov_60meses\", 0)\n",
    "\n",
    "    ## Adicionar os proventos\n",
    "    df_Tratar_por_Acao.loc[:, \"Prov_12meses\"] = df_Tratar_por_Acao.apply(lambda x: x[\"DY_12m\"]*x[\"Preco_fechamento\"], axis=1)\n",
    "    df_Tratar_por_Acao.loc[:, \"Prov_24meses\"] = df_Tratar_por_Acao.apply(lambda x: x[\"DY_24m\"]*x[\"Preco_fechamento\"], axis=1)\n",
    "    df_Tratar_por_Acao.loc[:, \"Prov_36meses\"] = df_Tratar_por_Acao.apply(lambda x: x[\"DY_36m\"]*x[\"Preco_fechamento\"], axis=1)\n",
    "    df_Tratar_por_Acao.loc[:, \"Prov_48meses\"] = df_Tratar_por_Acao.apply(lambda x: x[\"DY_48m\"]*x[\"Preco_fechamento\"], axis=1)\n",
    "    df_Tratar_por_Acao.loc[:, \"Prov_60meses\"] = df_Tratar_por_Acao.apply(lambda x: x[\"DY_60m\"]*x[\"Preco_fechamento\"], axis=1)\n",
    "\n",
    "    # Computar os desdobramentos, grupamentos e Bonificações\n",
    "    if Existe_eventos:\n",
    "        ## Datas do Eventos com a condição de Classe de Ação\n",
    "        datas_eventos = df_eventos.loc[:].index\n",
    "\n",
    "\n",
    "        ## Loop para percorrer as datas dos eventos e alterar o número equivalente de ações\n",
    "        for data in datas_eventos:\n",
    "            \n",
    "            ## Fator do evento\n",
    "            condicao_even = (df_eventos.index == data)\n",
    "            fator_evento = df_eventos.loc[condicao_even,\"Fator\"].prod()\n",
    "\n",
    "            ## Condição para recalcular o número de ações equivalentes, no df_Tratar_por_Acao\n",
    "            ## Lembrar que \"data\" é a \"data-com\" do evento, portanto está incluída\n",
    "            condicao = df_Tratar_por_Acao.index <= data\n",
    "            ## Recalcular o número de ações equivalentes\n",
    "            df_Tratar_por_Acao.loc[condicao,\"Num_acoes_equivalentes\"] = df_Tratar_por_Acao.loc[condicao,\"Num_acoes_equivalentes\"]/fator_evento\n",
    "\n",
    "            ## Recalcular os proventos\n",
    "            df_Tratar_por_Acao.loc[condicao,\"Prov_12meses\"] = df_Tratar_por_Acao.loc[condicao,\"Prov_12meses\"]*fator_evento\n",
    "            df_Tratar_por_Acao.loc[condicao,\"Prov_24meses\"] = df_Tratar_por_Acao.loc[condicao,\"Prov_24meses\"]*fator_evento\n",
    "            df_Tratar_por_Acao.loc[condicao,\"Prov_36meses\"] = df_Tratar_por_Acao.loc[condicao,\"Prov_36meses\"]*fator_evento\n",
    "            df_Tratar_por_Acao.loc[condicao,\"Prov_48meses\"] = df_Tratar_por_Acao.loc[condicao,\"Prov_48meses\"]*fator_evento\n",
    "            df_Tratar_por_Acao.loc[condicao,\"Prov_60meses\"] = df_Tratar_por_Acao.loc[condicao,\"Prov_60meses\"]*fator_evento\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ## Adicionar o Ticker\n",
    "    df_Tratar_por_Acao.insert(len(df_Tratar_por_Acao.columns), \"Fonte\", \"Comdinheiro\")\n",
    "\n",
    "\n",
    "    ## Normalizar os dados pelo número de ações equivalentes\n",
    "    colunas_divididas = ['PL', 'RL', 'EBITDA', 'D&A', 'EBIT', 'LL',\n",
    "                        'LL_controlador', 'LL_nao_controlador', \n",
    "                        'Div_Bruta', 'Div_liq', 'Div_Arrendamento', 'FCO', 'FCI', 'FCF']\n",
    "    for col in colunas_divididas:\n",
    "        df_Tratar_por_Acao.loc[:, col] = df_Tratar_por_Acao.apply(lambda row: row[col]/row['Num_acoes_equivalentes'], axis=1)\n",
    "\n",
    "    return df_Tratar_por_Acao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ajuste_cotacoes(df_cot, df_Tratar_por_Acao, df_eventos, Existe_eventos, Ticker):\n",
    "    ## Tratar o dataframe das cotações com os eventos\n",
    "    df_cot_tratado = df_cot.loc[:,[\"Fech_Historico\",\"Fech_Ajustado\"]].copy()\n",
    "    df_cot_tratado.columns = [\"Fechamento_Equivalente\",\"Fech_Ajustado\"]\n",
    "    df_cot_tratado.insert(0,\"Num_acoes_equivalentes\",0)\n",
    "\n",
    "    ## Filtrar as datas do df_Tratar_por_Acao menores que a data do df_cot_tratado\n",
    "    datas_fund = df_Tratar_por_Acao.index\n",
    "    datas_cot = df_cot_tratado.index\n",
    "    ## Loop para percorrer as datas dos eventos e alterar o número equivalente de ações\n",
    "    ## Considerando a Classe da ação. Lembrar que o Num_acoes_equivalentes calculado anteriormente\n",
    "    ## só foi calculado para cada trimestre, aqui considera o número de ações equivalentes para cada dia\n",
    "    for data in datas_cot:\n",
    "        condicao = datas_fund <= data\n",
    "        # Se todos forem falso pode deletar a linha\n",
    "        if condicao.sum() > 0:\n",
    "            Num_acoes = df_Tratar_por_Acao.loc[condicao,\"Num_acoes\"][0]\n",
    "            Fator_equivalencia_acoes = df_Tratar_por_Acao.loc[condicao,\"Fator_equivalencia_acoes\"][0]\n",
    "            df_cot_tratado.loc[data,\"Num_acoes_equivalentes\"] = Num_acoes / Fator_equivalencia_acoes\n",
    "            #print(data, Num_acoes, Fator_equivalencia_acoes)\n",
    "        else:\n",
    "            df_cot_tratado.drop(data, inplace=True)\n",
    "            Num_acoes = 0\n",
    "            Fator_equivalencia_acoes = 0\n",
    "\n",
    "\n",
    "    ## Normalizar os dados pelo número de ações equivalentes, considerando os eventos\n",
    "\n",
    "    if Existe_eventos:\n",
    "        datas_eventos = df_eventos.index\n",
    "        for data in datas_eventos:\n",
    "            \n",
    "            ## Fator do evento\n",
    "            condicao_evento = (df_eventos.index == data)\n",
    "            fator_evento = df_eventos.loc[condicao_evento,\"Fator\"].prod()\n",
    "\n",
    "            ## Condição para recalcular o Preço de Fechamento Histórico, no df_cot_tratado\n",
    "            condicao = df_cot_tratado.index <= data\n",
    "            ## Recalcular o preço Equivalente\n",
    "            df_cot_tratado.loc[condicao,\"Fechamento_Equivalente\"] = df_cot_tratado.loc[condicao,\"Fechamento_Equivalente\"]*fator_evento\n",
    "\n",
    "            ## Recalcular o número de ações equivalentes\n",
    "            df_cot_tratado.loc[condicao,\"Num_acoes_equivalentes\"] = df_cot_tratado.loc[condicao,\"Num_acoes_equivalentes\"]/fator_evento\n",
    "        \n",
    "    ## Adicionar o Ticker\n",
    "    df_cot_tratado.insert(0, \"Ticker\", Ticker)\n",
    "    # Adicionar o Coluna de Market Value\n",
    "    df_cot_tratado.insert(len(df_cot_tratado.columns), \"Market_value\", 0)\n",
    "    df_cot_tratado.loc[:,\"Market_value\"] = df_cot_tratado.apply(lambda row: row[\"Fechamento_Equivalente\"]*row[\"Num_acoes_equivalentes\"], axis=1)\n",
    "\n",
    "    # Fonte\n",
    "    df_cot_tratado.insert(len(df_cot_tratado.columns), \"Fonte\", \"Comdinheiro\")\n",
    "    \n",
    "    return df_cot_tratado\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ajuste_prov(df_prov, df_eventos, Existe_prov, Existe_eventos):\n",
    "    \n",
    "\n",
    "    ## Considerar os eventos de desdobramentos, grupamentos e bonificações\n",
    "    if Existe_prov:\n",
    "        ## Tratar o dataframe de proventos com os eventos\n",
    "        df_prov_tratado = df_prov.copy()\n",
    "        df_prov_tratado.insert(0,\"Provento_Efeitivo\",0)\n",
    "\n",
    "        ## Descontar imposto do JCP\n",
    "        df_prov_tratado.loc[:, \"Provento_Efeitivo\"] = \\\n",
    "            df_prov_tratado.apply(lambda row: row[\"Valor_do_Provento\"]*0.85 if row[\"Tipo_do_Provento\"]==\"JCP\" else row[\"Valor_do_Provento\"], axis=1)\n",
    "        \n",
    "        if Existe_eventos:\n",
    "            datas_eventos = df_eventos.index\n",
    "            for data in datas_eventos:\n",
    "                \n",
    "                ## Fator do evento\n",
    "                condicao = (df_eventos.index == data)\n",
    "                fator_evento = df_eventos.loc[condicao,\"Fator\"].prod()\n",
    "\n",
    "                ## Condição para recalcular o Preço de Fechamento Histórico, no df_cot_tratado\n",
    "                condicao = df_prov_tratado.index <= data\n",
    "                ## Recalcular o número de ações equivalentes\n",
    "                df_prov_tratado.loc[condicao,\"Provento_Efeitivo\"] = df_prov_tratado.loc[condicao,\"Provento_Efeitivo\"]*fator_evento\n",
    "\n",
    "        return df_prov_tratado\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Múltiplos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiplos_diarios(df_Tratar_por_Acao, df_cot_tratado, Ticker):\n",
    "    # Coletando as datas de balanço e cotação\n",
    "    data_cotacao = df_cot_tratado.index\n",
    "    data_balanco = df_Tratar_por_Acao.index[0:-4]\n",
    "    primeiro_balanco = data_balanco[-1]\n",
    "    data_multiplos_diarios = data_cotacao[data_cotacao >= primeiro_balanco]\n",
    "\n",
    "    # Criando um DataFrame de múltiplos com as datas de balanço e cotação, Trimetre e Anual\n",
    "    df_multiplos_diarios_tri = pd.DataFrame(index=data_multiplos_diarios,\n",
    "    columns=[\"Num_acoes_equivalentes\",\"Fechamento_Equivalente\",\"Fech_Ajustado\", \n",
    "             \"Market_value\", \"EV\", \"EV_arrend\",\n",
    "            \"PVPA\",\"PSR\",\"EV_EBITDA\",\"EV_EBITDA_Arr\",\"P_EBIT\",\"PE\", \"PE_C\",\n",
    "            \"FCO\",\"FCI\",\"FCF\",\n",
    "            \"ROE\", \"Margem_liquida\",\"Margem_EBITDA\",\n",
    "            \"DIV_Bruta_PL\",\"DIV_liq_EBITDA\",\"DIV_Arrendamento_EBITDA\",\n",
    "            'DY_12m', 'DY_24m', 'DY_36m', 'DY_48m', 'DY_60m', \"DY_medio\" ,\"Fonte\"])\n",
    "\n",
    "\n",
    "    ## Preenchendo os dados de cotação\n",
    "    df_multiplos_diarios_tri.insert(0, \"Ticker\", Ticker)\n",
    "    df_multiplos_diarios_tri.loc[:, \"Fonte\"] = \"Comdinheiro\"\n",
    "\n",
    "    # Preenchendo alguns valores\n",
    "    lista_colunas = [\"Num_acoes_equivalentes\",\"Fechamento_Equivalente\",\"Fech_Ajustado\", \"Market_value\"]\n",
    "    df_multiplos_diarios_tri.loc[:, lista_colunas]\\\n",
    "        = df_cot_tratado.loc[:, lista_colunas]\n",
    "\n",
    "    ## Criano o DF de múltiplos diários com os dados fundamentalistas anuais\n",
    "    df_multiplos_diarios_anual = df_multiplos_diarios_tri.copy()\n",
    "\n",
    "    # Preenchendo os valores Absolutos\n",
    "    for data in data_multiplos_diarios:\n",
    "        condicao = df_Tratar_por_Acao.loc[:,\"Data_balanco\"] <= data\n",
    "        #print(data, condicao)\n",
    "        if condicao.sum()>0:\n",
    "            Preco_equivalente = df_multiplos_diarios_tri.loc[data,\"Fechamento_Equivalente\"]\n",
    "            ## EV = Market_value + Div_liq; Atenção que não foi considerado a dívida de arrendamento\n",
    "            EV = Preco_equivalente + df_Tratar_por_Acao.loc[condicao,\"Div_liq\"][0]\n",
    "            EV_Arrend = EV + df_Tratar_por_Acao.loc[condicao,\"Div_Arrendamento\"][0]\n",
    "\n",
    "            ## Atribuindo os valores de EV\n",
    "            df_multiplos_diarios_tri.loc[data,\"EV\"] = EV\n",
    "            df_multiplos_diarios_anual.loc[data,\"EV\"] = EV\n",
    "            df_multiplos_diarios_tri.loc[data,\"EV_arrend\"] = EV_Arrend\n",
    "            df_multiplos_diarios_anual.loc[data,\"EV_arrend\"] = EV_Arrend\n",
    "\n",
    "            ## PVPA -> Preço / PL\n",
    "            PL = df_Tratar_por_Acao.loc[condicao,\"PL\"][0]\n",
    "            PVPA = Preco_equivalente / PL\n",
    "            df_multiplos_diarios_tri.loc[data,\"PVPA\"] = PVPA\n",
    "            df_multiplos_diarios_anual.loc[data,\"PVPA\"] = PVPA\n",
    "\n",
    "\n",
    "            ## Dados Fundamentalistas de 1 ano\n",
    "            Receita_12meses = df_Tratar_por_Acao.loc[condicao,\"RL\"][:4].sum()\n",
    "            EBITDA_12meses = df_Tratar_por_Acao.loc[condicao,\"EBITDA\"][:4].sum()\n",
    "            EBIT_12meses = df_Tratar_por_Acao.loc[condicao,\"EBIT\"][:4].sum()\n",
    "            LL_12meses = df_Tratar_por_Acao.loc[condicao,\"LL\"][:4].sum()\n",
    "            LL_C_12meses = df_Tratar_por_Acao.loc[condicao,\"LL_controlador\"][:4].sum()\n",
    "            Div_liq_12meses = df_Tratar_por_Acao.loc[condicao,\"Div_liq\"][:1].sum()\n",
    "            Div_bruta_12meses = df_Tratar_por_Acao.loc[condicao,\"Div_Bruta\"][:1].sum()\n",
    "            Div_liq_Arr_12meses = Div_liq_12meses + df_Tratar_por_Acao.loc[condicao,\"Div_Arrendamento\"][:1].sum()\n",
    "            FCO_12meses = df_Tratar_por_Acao.loc[condicao,\"FCO\"][:4].sum()\n",
    "            FCI_12meses = df_Tratar_por_Acao.loc[condicao,\"FCI\"][:4].sum()\n",
    "            FCF_12meses = df_Tratar_por_Acao.loc[condicao,\"FCF\"][:4].sum()\n",
    "\n",
    "\n",
    "            ## Dados Fundamentalistas de 3 meses\n",
    "            Receita_3meses = df_Tratar_por_Acao.loc[condicao,\"RL\"][:1].sum()*4\n",
    "            EBITDA_3meses = df_Tratar_por_Acao.loc[condicao,\"EBITDA\"][:1].sum()*4\n",
    "            EBIT_3meses = df_Tratar_por_Acao.loc[condicao,\"EBIT\"][:1].sum()*4\n",
    "            LL_3meses = df_Tratar_por_Acao.loc[condicao,\"LL\"][:1].sum()*4\n",
    "            LL_C_3meses = df_Tratar_por_Acao.loc[condicao,\"LL_controlador\"][:1].sum()*4\n",
    "            Div_liq_3meses = Div_liq_12meses\n",
    "            Div_bruta_3meses = Div_bruta_12meses\n",
    "            Div_liq_Arr_3meses = Div_liq_Arr_12meses\n",
    "            FCO_3meses = df_Tratar_por_Acao.loc[condicao,\"FCO\"][:1].sum()*4\n",
    "            FCI_3meses = df_Tratar_por_Acao.loc[condicao,\"FCI\"][:1].sum()*4\n",
    "            FCF_3meses = df_Tratar_por_Acao.loc[condicao,\"FCF\"][:1].sum()*4\n",
    "\n",
    "            ## Registrando os dados de 1 ano\n",
    "            df_multiplos_diarios_anual.loc[data,\"PSR\"] = Preco_equivalente / Receita_12meses if Receita_12meses != 0 else 0\n",
    "            df_multiplos_diarios_anual.loc[data,\"EV_EBITDA\"] = EV / EBITDA_12meses if EBITDA_12meses != 0 else 0\n",
    "            df_multiplos_diarios_anual.loc[data,\"EV_EBITDA_Arr\"] = EV_Arrend / EBITDA_12meses if EBITDA_12meses != 0 else 0\n",
    "            df_multiplos_diarios_anual.loc[data,\"P_EBIT\"] = Preco_equivalente / EBIT_12meses if EBIT_12meses != 0 else 0\n",
    "            df_multiplos_diarios_anual.loc[data,\"PE\"] = Preco_equivalente / LL_12meses if LL_12meses != 0 else 0\n",
    "            df_multiplos_diarios_anual.loc[data,\"PE_C\"] = Preco_equivalente / LL_C_12meses if LL_C_12meses != 0 else 0\n",
    "            df_multiplos_diarios_anual.loc[data,\"FCO\"] = Preco_equivalente / FCO_12meses if FCO_12meses != 0 else 0\n",
    "            df_multiplos_diarios_anual.loc[data,\"FCI\"] = Preco_equivalente / FCI_12meses if FCI_12meses != 0 else 0\n",
    "            df_multiplos_diarios_anual.loc[data,\"FCF\"] = Preco_equivalente / FCF_12meses if FCF_12meses != 0 else 0\n",
    "            df_multiplos_diarios_anual.loc[data,\"ROE\"] = LL_12meses / PL if PL != 0 else 0\n",
    "            df_multiplos_diarios_anual.loc[data,\"Margem_liquida\"] = LL_12meses / Receita_12meses if Receita_12meses != 0 else 0\n",
    "            df_multiplos_diarios_anual.loc[data,\"Margem_EBITDA\"] = EBITDA_12meses / Receita_12meses if Receita_12meses != 0 else 0\n",
    "            df_multiplos_diarios_anual.loc[data,\"DIV_Bruta_PL\"] = Div_bruta_12meses / PL if PL != 0 else 0\n",
    "            df_multiplos_diarios_anual.loc[data,\"DIV_liq_EBITDA\"] = Div_liq_12meses / EBITDA_12meses if EBITDA_12meses != 0 else 0\n",
    "            df_multiplos_diarios_anual.loc[data,\"DIV_Arrendamento_EBITDA\"] = Div_liq_Arr_3meses / EBITDA_12meses if EBITDA_12meses != 0 else 0\n",
    "\n",
    "\n",
    "            ## Registrando os dados de 3 meses\n",
    "            df_multiplos_diarios_tri.loc[data,\"PSR\"] = Preco_equivalente / Receita_3meses if Receita_3meses != 0 else 0\n",
    "            df_multiplos_diarios_tri.loc[data,\"EV_EBITDA\"] = EV / EBITDA_3meses if EBITDA_3meses != 0 else 0\n",
    "            df_multiplos_diarios_tri.loc[data,\"EV_EBITDA_Arr\"] = EV_Arrend / EBITDA_3meses if EBITDA_3meses != 0 else 0\n",
    "            df_multiplos_diarios_tri.loc[data,\"P_EBIT\"] = Preco_equivalente / EBIT_3meses if EBIT_3meses != 0 else 0\n",
    "            df_multiplos_diarios_tri.loc[data,\"PE\"] = Preco_equivalente / LL_3meses if LL_3meses != 0 else 0\n",
    "            df_multiplos_diarios_tri.loc[data,\"PE_C\"] = Preco_equivalente / LL_C_3meses if LL_C_3meses != 0 else 0\n",
    "            df_multiplos_diarios_tri.loc[data,\"FCO\"] = Preco_equivalente / FCO_3meses if FCO_3meses != 0 else 0\n",
    "            df_multiplos_diarios_tri.loc[data,\"FCI\"] = Preco_equivalente / FCI_3meses if FCI_3meses != 0 else 0\n",
    "            df_multiplos_diarios_tri.loc[data,\"FCF\"] = Preco_equivalente / FCF_3meses if FCF_3meses != 0 else 0\n",
    "            df_multiplos_diarios_tri.loc[data,\"ROE\"] = LL_3meses / PL if PL != 0 else 0\n",
    "            df_multiplos_diarios_tri.loc[data,\"Margem_liquida\"] = LL_3meses / Receita_3meses if Receita_3meses != 0 else 0\n",
    "            df_multiplos_diarios_tri.loc[data,\"Margem_EBITDA\"] = EBITDA_3meses / Receita_3meses if Receita_3meses != 0 else 0\n",
    "            df_multiplos_diarios_tri.loc[data,\"DIV_Bruta_PL\"] = Div_bruta_3meses / PL if PL != 0 else 0\n",
    "            df_multiplos_diarios_tri.loc[data,\"DIV_liq_EBITDA\"] = Div_liq_3meses / EBITDA_3meses if EBITDA_3meses != 0 else 0\n",
    "            df_multiplos_diarios_tri.loc[data,\"DIV_Arrendamento_EBITDA\"] = Div_liq_Arr_3meses / EBITDA_3meses if EBITDA_3meses != 0 else 0\n",
    "            \n",
    "\n",
    "\n",
    "            ## Adicionar os proventos\n",
    "            df_multiplos_diarios_tri.loc[data, \"DY_12m\":\"DY_60m\"] = 0\n",
    "            # Proventos\n",
    "            Prov_1ano = df_Tratar_por_Acao.loc[condicao, \"Prov_12meses\"][0]\n",
    "            Prov_2ano = df_Tratar_por_Acao.loc[condicao, \"Prov_24meses\"][0]/2\n",
    "            Prov_3ano = df_Tratar_por_Acao.loc[condicao, \"Prov_36meses\"][0]/3\n",
    "            Prov_4ano = df_Tratar_por_Acao.loc[condicao, \"Prov_48meses\"][0]/4\n",
    "            Prov_5ano = df_Tratar_por_Acao.loc[condicao, \"Prov_60meses\"][0]/5\n",
    "\n",
    "            ## Salvando o DY médio\n",
    "\n",
    "            df_multiplos_diarios_anual.loc[data, \"DY_12m\"] = Prov_1ano/ Preco_equivalente\n",
    "            df_multiplos_diarios_anual.loc[data, \"DY_24m\"] = Prov_2ano/ (Preco_equivalente)\n",
    "            df_multiplos_diarios_anual.loc[data, \"DY_36m\"] = Prov_3ano/ (Preco_equivalente)\n",
    "            df_multiplos_diarios_anual.loc[data, \"DY_48m\"] = Prov_4ano/ (Preco_equivalente)\n",
    "            df_multiplos_diarios_anual.loc[data, \"DY_60m\"] = Prov_5ano/ (Preco_equivalente)\n",
    "\n",
    "            df_multiplos_diarios_anual.loc[data, \"DY_medio\"] = (Prov_2ano + Prov_3ano + Prov_4ano + Prov_5ano)/ (Preco_equivalente*4) ## Descartar o último ano para evitar distorções\n",
    "\n",
    "\n",
    "    return df_multiplos_diarios_tri, df_multiplos_diarios_anual\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções para estimar o crescimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CalculoCAGRnAnos(serie):\n",
    "\n",
    "    copSerie = serie.copy()\n",
    "    menor_valor = copSerie.min()\n",
    "    maior_valor = copSerie.max()\n",
    "    copSerie.sort_index(ascending=True, inplace=True)\n",
    "\n",
    "    if maior_valor < 0:\n",
    "        print(\"Maior Valor menor que zero\")\n",
    "        return -1.01\n",
    "    elif menor_valor < 0:\n",
    "        copSerie = copSerie + (maior_valor- menor_valor)/2\n",
    "\n",
    "    copSerie = copSerie.apply(lambda x: np.log(x))\n",
    "    try:\n",
    "        expoente = np.polyfit(range(len(copSerie)), copSerie.values, 1)[0] # Highest power first\n",
    "    except:\n",
    "        expoente = 1\n",
    "        print(\"Erro no calculo do CAGR\")\n",
    "        print(serie)\n",
    "    CAGR = (np.exp(expoente))**4 -1 \n",
    "    return CAGR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Func_CAGR(df_Tratar_por_Acao, Ticker):\n",
    "    df_CAGR = pd.DataFrame(columns=[\"Ticker\",\"Fundamento\",\"CAGR_1\",\"CAGR_2\",\"CAGR_4\",\"CAGR_8\"])\n",
    "    Lista_Fundamentos = [\"RL\", \"EBITDA\", \"LL\", \"Proventos\"]\n",
    "    Lista_anos_CAGR = [1,2,4,8]\n",
    "\n",
    "    for fundamento in Lista_Fundamentos:\n",
    "        dados_fundamentalistas = df_Tratar_por_Acao.loc[:,fundamento]\n",
    "        dados_fundamentalistas = dados_fundamentalistas.copy()\n",
    "        df_CAGR_temp = pd.DataFrame(index=df_Tratar_por_Acao.index, columns=[\"Ticker\",\"Fundamento\",\"CAGR_1\",\"CAGR_2\",\"CAGR_4\",\"CAGR_8\"])\n",
    "        df_CAGR_temp.loc[:, \"Ticker\"] = Ticker\n",
    "        df_CAGR_temp.loc[:, \"Fundamento\"] = fundamento\n",
    "        for qtd_anos in Lista_anos_CAGR:\n",
    "            for data in df_Tratar_por_Acao.index:\n",
    "                ano = data.year\n",
    "                mes = data.month\n",
    "                dia = data.day\n",
    "                ## Data de início do corte\n",
    "                data_inicio = datetime(ano - qtd_anos, mes, dia-10)\n",
    "\n",
    "                condicao = (dados_fundamentalistas.index >= data_inicio) & \\\n",
    "                (dados_fundamentalistas.index <= data)\n",
    "\n",
    "                ## Cálculo do CAGR\n",
    "                serie = dados_fundamentalistas.loc[condicao]\n",
    "                if len(serie) >= qtd_anos*4:\n",
    "                    CAGR = CalculoCAGRnAnos(serie)\n",
    "                else:\n",
    "                    CAGR = 0\n",
    "\n",
    "                ## Salvando os dados no df_CAGR\n",
    "                df_CAGR_temp.loc[data, f\"CAGR_{qtd_anos}\"] = CAGR\n",
    "\n",
    "        ##  Salvando os dados no df_CAGR\n",
    "        df_CAGR = pd.concat([df_CAGR, df_CAGR_temp], axis=0)\n",
    "\n",
    "    ## Consertar os dados do CAGR do Provento\n",
    "    df_CAGR.loc[df_CAGR[\"Fundamento\"]==\"Proventos\", \"CAGR_1\":\"CAGR_8\"] = df_CAGR.loc[df_CAGR[\"Fundamento\"]==\"Proventos\", \"CAGR_1\":\"CAGR_8\"].apply(lambda x: (1+x)**0.25-1)\n",
    "\n",
    "    ## Se CAGR for maior do que 50% considerar como 50%\n",
    "    CAGR_Maximo = 2\n",
    "    df_CAGR.loc[df_CAGR[\"CAGR_1\"] > CAGR_Maximo, \"CAGR_1\"] = CAGR_Maximo\n",
    "    df_CAGR.loc[df_CAGR[\"CAGR_2\"] > CAGR_Maximo, \"CAGR_2\"] = CAGR_Maximo\n",
    "    df_CAGR.loc[df_CAGR[\"CAGR_4\"] > CAGR_Maximo, \"CAGR_4\"] = CAGR_Maximo\n",
    "    df_CAGR.loc[df_CAGR[\"CAGR_8\"] > CAGR_Maximo, \"CAGR_8\"] = CAGR_Maximo\n",
    "    \n",
    "\n",
    "    ## Calculando a média\n",
    "    df_CAGR.loc[:, \"CAGR_medio\"] = df_CAGR.loc[:, \"CAGR_2\":\"CAGR_8\"].mean(axis=1)  ## Descartar o último ano para evitar distorções\n",
    "    return df_CAGR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Função para tratar dados diários"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Tratar_dados_diarios(Ticker):\n",
    "    ## Endereço dos arquivos\n",
    "    arquivo_Fund, arquivo_Cot, arquivo_Prov, arquivo_Eventos, \\\n",
    "        arquivo_Subscricao = endereco_arquivos(Ticker)\n",
    "    \n",
    "    print(f\"Entrou em {Ticker}\")\n",
    "    ## Verificando a classe da ação\n",
    "    Classe_acao = Func_Classe_acao(Ticker)\n",
    "\n",
    "    ## Tratar dados Fundamentalistas\n",
    "    df_fund = tratar_Fund(arquivo_Fund)\n",
    "\n",
    "    ## Tratar dados de cotações\n",
    "    df_cot = tratar_cot(arquivo_Cot)\n",
    "\n",
    "    ## Tratar dados de proventos\n",
    "    df_prov, Existe_prov = tratar_prov(arquivo_Prov, Classe_acao)\n",
    "\n",
    "    ## Tratar dados de eventos\n",
    "    df_eventos, Existe_eventos = tratar_even(arquivo_Eventos, Classe_acao)\n",
    "\n",
    "    ## Tratar dados de subscrições\n",
    "    df_subscricao, Existe_subscricao = tratar_subs(arquivo_Subscricao)\n",
    "\n",
    "    ## Normalizar Dados Fundamentalistas e considerar os eventos\n",
    "    df_Tratar_por_Acao = normalizar_dados_fund(df_fund, df_eventos, Existe_eventos, Ticker)\n",
    "\n",
    "    ## Ajustar as cotações\n",
    "    df_cot_tratado = ajuste_cotacoes(df_cot, df_Tratar_por_Acao, df_eventos, Existe_eventos, Ticker)\n",
    "\n",
    "\n",
    "    ## Ajustar os proventos\n",
    "    df_prov_tratado = ajuste_prov(df_prov, df_eventos, Existe_prov, Existe_eventos)\n",
    "\n",
    "    ## Multiplos diários\n",
    "    df_multiplos_diarios_tri, df_multiplos_diarios_anual = multiplos_diarios(df_Tratar_por_Acao, df_cot_tratado, Ticker)\n",
    "\n",
    "    ## CAGR\n",
    "    df_CAGR = Func_CAGR(df_Tratar_por_Acao, Ticker)\n",
    "\n",
    "    ### Salvar os arquivos em parquet\n",
    "    # Salvar Fundamentos\n",
    "    nome_arquivo = f\"Dados_normalizados_acao_{Ticker}.parquet\"\n",
    "    arquivo_por_acao = os.path.join(\"..\",\"..\",\"..\",\"dataset\", \"BR\", \"ACOES\", \"Dados_Tratados\",nome_arquivo)\n",
    "    # Substitua os valores infinitos por NaN (ou qualquer outro valor desejado)\n",
    "    df_Tratar_por_Acao.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    df_Tratar_por_Acao.to_parquet(arquivo_por_acao, engine='fastparquet')\n",
    "\n",
    "    ## Salvar Múltiplos diários\n",
    "    nome_arquivo = f\"Multiplos_diarios_{Ticker}.parquet\"\n",
    "    arquivo_multiplos = os.path.join(\"..\",\"..\",\"..\",\"dataset\", \"BR\", \"ACOES\", \"Dados_Tratados\",nome_arquivo)\n",
    "    # Substitua os valores infinitos por NaN (ou qualquer outro valor desejado)\n",
    "    df_multiplos_diarios_anual.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    df_multiplos_diarios_anual.to_parquet(arquivo_multiplos, engine='fastparquet')\n",
    "\n",
    "    ## Salvar o CAGR\n",
    "    nome_arquivo = f\"CAGR_{Ticker}.parquet\"\n",
    "    arquivo_CAGR = os.path.join(\"..\",\"..\",\"..\",\"dataset\", \"BR\", \"ACOES\", \"Dados_Tratados\",nome_arquivo)\n",
    "    # Substitua os valores infinitos por NaN (ou qualquer outro valor desejado)\n",
    "    df_CAGR.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    df_CAGR.to_parquet(arquivo_CAGR, engine='fastparquet')\n",
    "\n",
    "    \n",
    "    return df_Tratar_por_Acao, df_multiplos_diarios_anual, df_CAGR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ler os ativos que serão buscados\n",
    "arquivo_busca = os.path.join(\"..\",\"..\",\"..\",\"dataset\", \"BR\", \"ACOES\", \"Dados_Brutos\",\"Lista_Ativos_Busca.parquet\")\n",
    "Lista_ativos_busca = pd.read_parquet(arquivo_busca)\n",
    "Lista_ativos_busca = Lista_ativos_busca[\"Ticker\"].to_list()\n",
    "Lista_ativos_busca.sort()\n",
    "Lista_ativos_nao_deu_certo = []\n",
    "for Ticker in Lista_ativos_busca:\n",
    "    try:\n",
    "        df_Tratar_por_Acao, df_multiplos_diarios_anual, df_CAGR = Tratar_dados_diarios(Ticker)\n",
    "        print(f\"Deu certo {Ticker}\")\n",
    "    except:\n",
    "        print(f\"Não deu certo {Ticker}\")\n",
    "        Lista_ativos_nao_deu_certo.append(Ticker)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (WebScraping)",
   "language": "python",
   "name": "pycharm-555ee0c9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
